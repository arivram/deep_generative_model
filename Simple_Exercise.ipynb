{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb0a200-63d9-4c27-b944-38d0f2a22622",
   "metadata": {},
   "source": [
    "## import statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d452afcd-0327-40b3-98a7-762e36db9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881722bb-d60c-4453-af85-462076dfed8c",
   "metadata": {},
   "source": [
    "## Load Files and set output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6b1335-c298-4643-a84b-fa6c23c310cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sound_directory = \"./input\"\n",
    "output_dataset_directory = \"./output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cb9c9-6448-46d2-bea7-32a0f93a1cdb",
   "metadata": {},
   "source": [
    "## Function to load and preprocess audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04b88b3-3500-47b9-a096-5805372595c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_audio_files(sound_directory, sr=16000):\n",
    "    audio_data = []\n",
    "    for filename in os.listdir(sound_directory):\n",
    "        if filename == '.DS_Store':\n",
    "            continue  # Skip .DS_Store file\n",
    "        file_path = os.path.join(sound_directory, filename)\n",
    "        audio, _ = librosa.load(file_path, sr=sr)\n",
    "        audio_data.append(audio)\n",
    "    return audio_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ac14f-97df-417a-b4d3-f279003dfe92",
   "metadata": {},
   "source": [
    "## Function to create the SampleRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72255664-e3da-4250-8b15-2b5ddb0b0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_samplernn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(256, input_shape=(None, 1), return_sequences=True))\n",
    "    model.add(layers.LSTM(256, return_sequences=True))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab317106-53c9-4a05-bee2-57b7869360b3",
   "metadata": {},
   "source": [
    "## Function to generate synthetic sound using the SampleRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3585ea20-d0c9-4990-acdf-e4ef41467070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_synthetic_sound(model, input_audio):\n",
    "    input_audio = np.expand_dims(input_audio, axis=-1)\n",
    "    synthetic_sound = model.predict(np.expand_dims(input_audio, axis=0))\n",
    "    return np.squeeze(synthetic_sound, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999eb97-62e0-4fe3-a906-1d0b5f3181e7",
   "metadata": {},
   "source": [
    "## Simple Main Function without hyperparemeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b86279-7315-46ca-8342-0fc663726f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 20:18:05.510776: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 89s 89s/step\n",
      "1/1 [==============================] - 113s 113s/step\n",
      "1/1 [==============================] - 96s 96s/step\n",
      "1/1 [==============================] - 42s 42s/step\n",
      "1/1 [==============================] - 46s 46s/step\n",
      "1/1 [==============================] - 85s 85s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the raw audio files\n",
    "    raw_audio_data = load_audio_files(input_sound_directory)\n",
    "    \n",
    "     # Remove the output folder if it already exists\n",
    "    if os.path.exists(output_dataset_directory):\n",
    "        shutil.rmtree(output_dataset_directory)\n",
    "\n",
    "    # Create a new output folder\n",
    "    os.makedirs(output_dataset_directory)\n",
    "\n",
    "    # Create and compile the SampleRNN model\n",
    "    model = create_samplernn_model()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    # Generate synthetic sound datasets for each input file\n",
    "    for idx, raw_audio in enumerate(raw_audio_data):\n",
    "        synthetic_datasets = []\n",
    "        for _ in range(3):  # Generate 3 unique synthetic datasets\n",
    "            synthetic_sound = generate_synthetic_sound(model, raw_audio)\n",
    "            synthetic_datasets.append(synthetic_sound)\n",
    "\n",
    "        # Save the synthetic datasets to the output directory\n",
    "        os.makedirs(output_dataset_directory, exist_ok=True)\n",
    "        for idx, synthetic_sound in enumerate(synthetic_datasets):\n",
    "            output_filename = f\"synthetic_sound_dataset_{idx}.wav\"\n",
    "            output_path = os.path.join(output_dataset_directory, output_filename)\n",
    "            sf.write(output_path, synthetic_sound, samplerate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
